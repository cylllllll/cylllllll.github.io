---
title: 逻辑回归 
categories: Machine Learning
date: 2019-05-07 10:00:00
mathjax: true


---

# 逻辑回归

> 从大的类别上来说，逻辑回归是一种有监督的统计学习方法，主要用于对样本进行分类。在线性回归模型中，输出一般是连续的，例如

$$
y=f(x)=ax+b
$$

> 对于每一个输入的x，都有一个对应的y输出。模型的定义域和值域都可以是[-∞, +∞]。但是对于逻辑回归，输入可以是连续的[-∞, +∞]，但输出一般是离散的，即只有有限多个输出值。例如，其值域可以只有两个值{0, 1}，这两个值可以表示对样本的某种分类，高/低、患病/健康、阴性/阳性等，这就是最常见的二分类逻辑回归。因此，从整体上来说，通过逻辑回归模型，我们将在整个实数范围上的x映射到了有限个点上，这样就实现了对x的分类。因为每次拿过来一个x，经过逻辑回归分析，就可以将它归入某一类y中。
>
> ​	逻辑回归也被称为广义线性回归模型，它与线性回归模型的形式基本上相同，都具有 ax+b，其中a和b是待求参数，其区别在于他们的因变量不同，多重线性回归直接将ax+b作为因变量，即y = ax+b，而logistic回归则通过函数S将ax+b对应到一个隐状态p，p = S(ax+b)，然后根据p与1-p的大小决定因变量的值。这里的函数S就是Sigmoid函数

$$
S(t)=\frac{1}{1+e−t}
$$

> 将t换成ax+b，可以得到逻辑回归模型的参数形式：

$$

$$

​	逻辑回归返回的是概率。可以使用返回的概率（例如，用户点击此广告的概率为 0.000054），也可以将返回的概率转换成二元值（例如，这封电子邮件是垃圾邮件）。为了将逻辑回归值映射到二元类别，必须指定分类阈值。如果值高于该阈值，则表示“垃圾邮件”；如果值低于该阈值，则表示“非垃圾邮件”。通常来说分类阈值应始终为 0.5，但阈值取决于具体问题，因此须根据情况进行调整。

该模型将 100 个分为真 （正类别）或假（负类别）

| 真正例（TP）             |
| ------------------------ |
| 真实情况：假             |
| 机器学习模型预测结果：假 |
| TP结果数：1              |

| 假正例（FP）             |
| ------------------------ |
| 真实情况：真             |
| 机器学习模型预测结果：假 |
| TP结果数：1              |

| 假负例（FN）             |
| ------------------------ |
| 真实情况：假             |
| 机器学习模型预测结果：真 |
| TP结果数：8              |

| 真负例（TN）             |
| ------------------------ |
| 真实情况：真             |
| 机器学习模型预测结果：真 |
| TP结果数：90             |

##  

### 准确率

准确率是指我们的模型预测正确的结果所占的比例
$$
Accuracy=\frac{TP+TN}{TP+TN+FP+FN}=\frac{1+90}{1+90+1+8}=0.91
$$
在 100 个样本中，91 个为真（90 个 TN 和 1 个 FP），9 个为假（1 个 TP 和 8 个 FN）。在 91 个真中，该模型将 90 个正确识别为真。但是，在 9 个假中，该模型仅将 1 个正确识别为假，9 个假中有 8 个未被识别。

当使用分类不平衡的数据集（比如正类别标签和负类别标签的数量之间存在明显差异）时，单单准确率一项并不能反映全面情况，准确率指标的效果就会很差。

### 精确率

即在被识别为正类别的样本中，实际上确实为正类别的比例是多少。

精确率的定义如下：
$$
Precision=\frac{TP}{TP+FP}=\frac{1}{1+1}=0.5
$$
在 100 个样本中，有1个为假实际也为假的（1个TP），还有一个为真实际为假的（1个FP）。精确率为 0.5，也就是说该模型在预测真假时的正确率是 50%。

### 召回率

即所有实际上为正类别样本中，被正确预测为正类别的比例是多少。
$$
Recall=\frac{TP}{TP+FN}=\frac{1}{1+8}=0.11
$$
该模型的召回率是 0.11，也就是说，该模型能够正确识别出所假的百分比是 11%

### 精确率和召回率

对于模型的有效性，需要同时考虑精确率和召回率，但是精确率和召回率总是负相关，提高精确率通常会降低召回率值。下面通过例子说明：

邮件归类为垃圾邮件或非垃圾邮件的样本数据：

![1](https://i.imgur.com/qCpGPMY.png)

预测为正的样本（8个TP、2个FP）中实际也为正（8个TP），此时的精确率为：
$$
Precision=\frac{TP}{TP+FP}=\frac{8}{2+8}=0.8
$$
实际为正的样本（共8个TP、3个FN），预测也为正（阈值右边有8个TP），此时的召回率为：
$$
Recall=\frac{TP}{TP+FN}=\frac{8}{8+3}=0.73
$$
此时我们提高阈值

![2](https://i.imgur.com/WXs8VRr.png)

预测为正的样本（7个TP、1个FP）中实际也为正（7个TP），此时的精确率为：
$$
Precision=\frac{TP}{TP+FP}=\frac{7}{7+1}=0.88
$$
实际为正的样本（7个TP、4个FN），预测也为正（阈值右边有7个TP），此时的召回率为：
$$
Recall=\frac{TP}{TP+FN}=\frac{7}{7+4}=0.64
$$
相反，降低阈值

![3](https://i.imgur.com/5G3lqbq.png)

预测为正的样本（7个TP、1个FP）中实际也为正（7个TP），此时的精确率为：
$$
Precision=\frac{TP}{TP+FP}=\frac{7}{7+1}=0.88
$$
所以，通常来说，提高分类阈值会减少假正例，从而提高精确率。降低分类阈值会提高召回率。

### ROC曲线

> 在选择特定的分类阈值后， 精确率和召回率值便都可以确定。但我们可能无法事先得知最合适的分类阈值， 而我们仍然想知道我们的模型质量如何。合理的做法是尝试使用 许多不同的分类阈值来评估我们的模型。事实上，我们有一个指标可衡量 模型在所有可能的分类阈值下的效果。该指标称为ROC曲线，即接收者操作特征曲线。
>
> ROC 曲线用于绘制采用不同分类阈值时的精确率与召回率。降低分类阈值会导致将更多样本归为正类别，从而增加假正例和真正例的个数。下图显示了一个典型的 ROC 曲线。
>
> ![2972843068-5af547dd014af_articlex](https://i.imgur.com/SA1aycx.png)
>
> 为了计算 ROC 曲线上的点，我们可以使用不同的分类阈值多次评估逻辑回归模型，但这样做效率非常低。幸运的是，有一种基于排序的高效算法可以为我们提供此类信息，这种算法称为曲线下面积。



### 代码

样本数据：

```
-0.017612	14.053064	0
-1.395634	4.662541	1
-0.752157	6.538620	0
-1.322371	7.152853	0
0.423363	11.054677	0
0.406704	7.067335	1
0.667394	12.741452	0
-2.460150	6.866805	1
0.569411	9.548755	0
-0.026632	10.427743	0
0.850433	6.920334	1
1.347183	13.175500	0
1.176813	3.167020	1
-1.781871	9.097953	0
-0.566606	5.749003	1
0.931635	1.589505	1
-0.024205	6.151823	1
-0.036453	2.690988	1
-0.196949	0.444165	1
1.014459	5.754399	1
1.985298	3.230619	1
-1.693453	-0.557540	1
-0.576525	11.778922	0
-0.346811	-1.678730	1
-2.124484	2.672471	1
1.217916	9.597015	0
-0.733928	9.098687	0
-3.642001	-1.618087	1
0.315985	3.523953	1
1.416614	9.619232	0
-0.386323	3.989286	1
0.556921	8.294984	1
1.224863	11.587360	0
-1.347803	-2.406051	1
1.196604	4.951851	1
0.275221	9.543647	0
0.470575	9.332488	0
-1.889567	9.542662	0
-1.527893	12.150579	0
-1.185247	11.309318	0
-0.445678	3.297303	1
1.042222	6.105155	1
-0.618787	10.320986	0
1.152083	0.548467	1
0.828534	2.676045	1
-1.237728	10.549033	0
-0.683565	-2.166125	1
0.229456	5.921938	1
-0.959885	11.555336	0
0.492911	10.993324	0
0.184992	8.721488	0
-0.355715	10.325976	0
-0.397822	8.058397	0
0.824839	13.730343	0
1.507278	5.027866	1
0.099671	6.835839	1
-0.344008	10.717485	0
1.785928	7.718645	1
-0.918801	11.560217	0
-0.364009	4.747300	1
-0.841722	4.119083	1
0.490426	1.960539	1
-0.007194	9.075792	0
0.356107	12.447863	0
0.342578	12.281162	0
-0.810823	-1.466018	1
2.530777	6.476801	1
1.296683	11.607559	0
0.475487	12.040035	0
-0.783277	11.009725	0
0.074798	11.023650	0
-1.337472	0.468339	1
-0.102781	13.763651	0
-0.147324	2.874846	1
0.518389	9.887035	0
1.015399	7.571882	0
-1.658086	-0.027255	1
1.319944	2.171228	1
2.056216	5.019981	1
-0.851633	4.375691	1
-1.510047	6.061992	0
-1.076637	-3.181888	1
1.821096	10.283990	0
3.010150	8.401766	1
-1.099458	1.688274	1
-0.834872	-1.733869	1
-0.846637	3.849075	1
1.400102	12.628781	0
1.752842	5.468166	1
0.078557	0.059736	1
```

根据学习内容尝试测试逻辑回归算法：

```python
# 从文件中读取样本数据
def loadDataSet(p, file_n):
    dataMat = [];
    labelMat = []
    fr = open(os.path.join(p, file_n))
    for line in fr.readlines():
        lineArr = line.strip().split()
        dataMat.append([1.0, float(lineArr[0]), float(lineArr[1])])  
        # 三个特征x0, x1, x2
        labelMat.append(int(lineArr[2]))
    return dataMat, labelMat
def sigmoid(inX):
     return 1.0/(1+exp(-inX))
```

梯度下降法求回归系数a，由于样本量少，所以将迭代次数改成了1000次：

```python
def gradAscent(dataMatIn, classLabels):
    # convert to NumPy matrix
    dataMatrix = mat(dataMatIn)
    labelMat = mat(classLabels).transpose()
    m, n = shape(dataMatrix)
    alpha = 0.001  # 学习率
    maxCycles = 1000
    weights = ones((n, 1))
    for k in range(maxCycles):
        # 模型预测值, 90 x 1
        h = sigmoid(dataMatrix * weights)
        # 真实值与预测值之间的误差, 90 x 1
        error = h - labelMat
        # 交叉熵代价函数对所有参数的偏导数, 3 x 1
        temp = dataMatrix.transpose() * error
        # 更新权重
        weights = weights - alpha * temp
    return weights

```

分类效果展示，参数weights就是回归系数：

```python
def plotBestFit(weights):
    import matplotlib.pyplot as plt
    dataMat, labelMat = loadDataSet(path, training_sample)
    dataArr = array(dataMat)
    n = shape(dataArr)[0]
    xcord1 = [];
    ycord1 = []
    xcord2 = [];
    ycord2 = []
    for i in range(n):
        if int(labelMat[i]) == 1:
            xcord1.append(dataArr[i, 1]);
            ycord1.append(dataArr[i, 2])
        else:
            xcord2.append(dataArr[i, 1]);
            ycord2.append(dataArr[i, 2])
    fig = plt.figure()
    ax = fig.add_subplot(111)
    ax.scatter(xcord1, ycord1, s=30, c='red', marker='s')
    ax.scatter(xcord2, ycord2, s=30, c='green')
    x = arange(-3.0, 3.0, 0.1)
    y = (-weights[0] - weights[1] * x) / weights[2] 
    ax.plot(x.reshape(1, -1), y.reshape(1, -1))
    plt.xlabel('X1');
    plt.ylabel('X2');
    plt.show()
```

展示结果：
![屏幕快照 2019-04-30 下午11.55.27 上午](https://i.imgur.com/OTb7zuP.png)